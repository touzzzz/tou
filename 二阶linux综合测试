DCDBC ABADC ACAAA BCADA CABDB AACBA
ABCD AB ABCD ABC ABCD ABCD ABCD ABC ABCD ABC
AABAA ABABA

ELK的架构是一个分布式架构，它包括多个节点组成一个集群，每个节点都可以扮演不同的角色，包括数据节点、Master节点和客户端节点等。其中，数据节点主要用于数据的存储和索引，Master节点用于集群的管理和控制，客户端节点则是用户与集群交互的入口。ELK的架构和组件在大数据场景中广泛应用，可以对海量的日志和数据进行实时分析和可视化，帮助用户更好地管理和优化系统性能，提高数据分析的效率和精度。

ELFK是一套基于开源软件的日志管理解决方案，包括Elasticsearch 、Logstash、Filebeat和Kibana亖个组件，下面对它们的架构和组件进行介绍

1.Elasticsearch（ES）：ES是一个基于Lucene的分布式搜索和分析引擎，它可以将海量的数据进行实时索引和搜索，支持高可用性和可扩展性，并且提供了丰富的RESTful API，方便用户进行数据操作和管理。
2. Logstash：Logstash是一个开源的数据收集引擎，它可以将来自各种来源的数据进行收集、处理和转换，支持多种输入和输出格式，包括文本、日志、JSON、CSV等，同时还支持数据过滤和转换、多种编解码方式等功能。
3.Filebeat：Filebeat是用于转发和集中日志数据的轻量级传送工具。Filebeat监视您指定的日志文件或位置，收集日志事件，并将它们转发到Elasticsearch或 Logstash进行索引，filebeat更轻量，占用资源更少，但logstash具有filter功能，能过滤分析日志
4.Kibana：Kibana是一个基于ES的可视化分析平台，它可以帮助用户实时监控和分析数据，生成丰富的图表和可视化报表，支持各种查询和过滤方式，同时还提供了高级的搜索和分析功能，包括聚合分析、地理信息分析等。



两个日志三个线程
1、从库生成两个线程，一个 I/O 线程，一个 SQL 线程;
2、I/O 线程去请求主库的 binlog，并将得到的 binlog 日志写到 relay log(中继日志) 文件中;
3、主库会生成一个 log dump 线程，用来给从库 I/O 线程传 binlog;
4、SQL 线程会读取 relay log 文件中的日志，并解析成具体操作，来实现主从的操作一致，而最终数据一致;


Master节点

kube-apiserver：API 服务器是 Kubernetes 控制平面的组件， 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。 API 服务器是 Kubernetes 控制平面的前端

etcd：一致且高可用的键值存储，用作 Kubernetes 所有集群数据的后台数据库。

kube-scheduler：kube-scheduler 是控制平面的组件， 负责监视新创建的、未指定运行节点（node）的 Pods， 并选择节点来让 Pod 在上面运行。

kube-controller-manager：kube-controller-manager 是控制平面的组件， 负责运行控制器进程

Node节点

kubelet：kubelet 会在集群中每个节点（node）上运行。 它保证容器（containers）都运行在 Pod 中。kubelet 不会管理不是由 Kubernetes 创建的容器

kube-proxy：kube-proxy 是集群中每个节点（node）上所运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。

容器运行时：这个基础组件使 Kubernetes 能够有效运行容器。 它负责管理 Kubernetes 环境中容器的执行和生命周期。

